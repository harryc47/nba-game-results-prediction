{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_curve, auc, roc_auc_score, precision_recall_curve, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "df = pd.read_csv(\n",
    "    '/Users/harry/CP/Study/MachineLearning/NBA-prediction/base_data/gameResults2015-20withMisPer100Player_for_use.csv',\n",
    "    index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('result', axis=1)\n",
    "y = df.result\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.fit_transform(X_test)\n",
    "\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print model performance\n",
    "print(neigh.score(X_train_std, y_train))\n",
    "print(neigh.score(X_test_std, y_test))\n",
    "y_pred = neigh.predict(X_test_std)\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(neigh, X_test_std, y_test, cmap=plt.cm.Blues)\n",
    "plot_confusion_matrix(neigh, X_test_std, y_test, normalize='true', cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ROC curve and auc\n",
    "\n",
    "# predict probabilities\n",
    "neigh_probs = neigh.predict_proba(X_test_std)\n",
    "neigh_probs = neigh_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "ns_probs = [0 for i in range(len(y_test))]\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "neigh_auc = roc_auc_score(y_test, neigh_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('KNN: ROC AUC=%.3f' % (neigh_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "neigh_fpr, neigh_tpr, _ = roc_curve(y_test, neigh_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(neigh_fpr, neigh_tpr, marker='.', label='KNN')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.title('ROC curve of KNN')\n",
    "pyplot.legend(loc='lower right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=33, max_iter=1000)\n",
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print model performance\n",
    "print(lr.score(X_train_std, y_train))\n",
    "print(lr.score(X_test_std, y_test))\n",
    "print(lr.score(X_combined_std, y_combined))\n",
    "y_pred = lr.predict(X_test_std)\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "plt.figure(figsize=[8,6],dpi=150)\n",
    "plot_confusion_matrix(lr, X_test_std, y_test, cmap=plt.cm.Blues)\n",
    "plot_confusion_matrix(lr, X_test_std, y_test, normalize='true', cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr.predict_proba(X_test_std)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "ns_probs = [0 for i in range(len(y_test))]\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.title('ROC curve of logistic regression')\n",
    "pyplot.legend(loc='lower right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall curve\n",
    "\n",
    "lr_probs = lr.predict_proba(X_test_std)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "\n",
    "y_hat = lr.predict(X_test_std)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(y_test, y_hat), auc(lr_recall, lr_precision)\n",
    "\n",
    "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
    "\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentative model, not for final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# rfc = RandomForestClassifier(random_state=33,**random_search.best_params_)\n",
    "# below the best_params_ are obtained from randomizedm search\n",
    "rfc = RandomForestClassifier(random_state=33,max_depth=6, max_features='log2', n_estimators=150)\n",
    "rfc.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print model performance\n",
    "print(rfc.score(X_train_std, y_train))\n",
    "print(rfc.score(X_test_std, y_test))\n",
    "y_pred = rfc.predict(X_test_std)\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "# plot_confusion_matrix(rfc, X_test_std, y_test, cmap=plt.cm.Blues)\n",
    "plot_confusion_matrix(rfc, X_test_std, y_test, normalize='true', display_labels=['Loss','Win'],\n",
    "                      cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature importances\n",
    "importances_rfc = rfc.feature_importances_*100\n",
    "indices_rfc = np.argsort(importances_rfc)[::-1]\n",
    "\n",
    "num_bars=20\n",
    "plt.figure(figsize=[8,6],dpi=150)\n",
    "plt.title(\"Important features That Determines the Game Results\")\n",
    "plt.barh(range(num_bars), importances_rfc[indices_rfc[range(num_bars-1,-1,-1)]])\n",
    "plt.yticks(range(num_bars), X.columns[indices_rfc[range(num_bars-1,-1,-1)]])\n",
    "plt.ylim([-1, num_bars])\n",
    "plt.xlabel(\"Relative Feature importance (%)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "# plt.grid(b=1,linestyle='--')\n",
    "# for a, b in enumerate(importances_rfc[indices_rfc[range(num_bars-1,-1,-1)]]):\n",
    "#     b=round(b,2)\n",
    "#     plt.text(b+3, a-0.3, '%s' % format(b,'.2f'), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Randomized Search Cross Validation with Time-series split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use randomized search to tune random forest\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': np.arange(30,211, 30),\n",
    "    'max_depth': randint(5,10),\n",
    "    'max_features': ['sqrt','log2'],\n",
    "    #'min_impurity_decrease': uniform(0,1),\n",
    "    #'min_samples_leaf': randint(1,1000)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=33),\n",
    "    parameters,                      \n",
    "#   scoring = 'precision',\n",
    "    cv=TimeSeriesSplit(n_splits=10),\n",
    "    n_iter=50,\n",
    "    random_state=33,\n",
    "    return_train_score=True,\n",
    "    scoring = 'f1'\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_std, y_train)\n",
    "\n",
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=1,kernel='linear', random_state=33)\n",
    "svc = svc.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot model performance\n",
    "print(svc.score(X_train_std, y_train))\n",
    "print(svc.score(X_test_std, y_test))\n",
    "y_pred = svc.predict(X_test_std)\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_confusion_matrix(svc, X_test_std, y_test, normalize='true', display_labels=['Loss','Win'],\n",
    "                      cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nonlinear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=0.1,kernel='rbf', probability=True,random_state=33)\n",
    "svc = svc.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot model performance\n",
    "print(svc.score(X_train_std, y_train))\n",
    "print(svc.score(X_test_std, y_test))\n",
    "y_pred = svc.predict(X_test_std)\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_confusion_matrix(svc, X_test_std, y_test, cmap=plt.cm.Blues)\n",
    "plot_confusion_matrix(svc, X_test_std, y_test, display_labels=['Loss','Win'],\n",
    "                             normalize='true', cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "# predict probabilities\n",
    "svc_probs = svc.predict_proba(X_test_std)\n",
    "svc_probs = svc_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "ns_probs = [0 for i in range(len(y_test))]\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "svc_auc = roc_auc_score(y_test, svc_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('SVM: ROC AUC=%.3f' % (svc_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "svc_fpr, svc_tpr, _ = roc_curve(y_test, svc_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(svc_fpr, svc_tpr, marker='.', label='SVM')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.title('ROC curve of SVM')\n",
    "pyplot.legend(loc='lower right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM: Grid Search Cross Validation with Time-series split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = {\n",
    "    'C':[0.1, 0.5, 1, 5],\n",
    "    'gamma': [1,0.1,0.01],\n",
    "    'kernel': ['linear','rbf','sigmoid']  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=33),             \n",
    "    parameters,                      \n",
    "    cv=TimeSeriesSplit(n_splits=10),\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate model graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# must run above codes to have the data\n",
    "\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill'+' (area = '+'%.2f'%(ns_auc)+')')\n",
    "pyplot.plot(neigh_fpr, neigh_tpr, linestyle='-', label='KNN'+' (area = '+'%.2f'%(neigh_auc)+')')\n",
    "pyplot.plot(lr_fpr, lr_tpr, linestyle='-', label='Logistic'+' (area = '+'%.2f'%(lr_auc)+')')\n",
    "pyplot.plot(rfc_fpr, rfc_tpr, linestyle='-', label='Random Forest'+' (area = '+'%.2f'%(rfc_auc)+')')\n",
    "pyplot.plot(svc_fpr, svc_tpr, linestyle='-', label='SVM'+' (area = '+'%.2f'%(svc_auc)+')')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.title('ROC curves')\n",
    "pyplot.legend(loc='lower right')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
